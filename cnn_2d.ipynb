{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Nhau6hODx_H"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten,Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cplzftzzROem"
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "\n",
    "maxlen = 100 #?\n",
    "batch_size = 50\n",
    "nb_filter = 64\n",
    "filter_length_1 = 10\n",
    "filter_length_2 = 7\n",
    "hidden_dims = 10\n",
    "nb_epoch = 30\n",
    "nb_classes = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YosiMd03RqAE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 train sequences\n",
      "270 test sequences\n",
      "X_train shape: (1080, 13, 1)\n",
      "X_test shape: (270, 13, 1)\n",
      "y_train shape: (1080,)\n",
      "y_test shape: (270,)\n"
     ]
    }
   ],
   "source": [
    "#load the MFCC data\n",
    "mfcc_filename = \"mfccs_dev_22050.csv\"\n",
    "dataset = pd.read_csv(mfcc_filename)\n",
    "df = pd.DataFrame(dataset)\n",
    "mfcc_data = df[[\"mfcc_mean1\",\"mfcc_mean2\",\"mfcc_mean3\",\"mfcc_mean4\",\"mfcc_mean5\",\"mfcc_mean6\",\"mfcc_mean7\",\"mfcc_mean8\",\"mfcc_mean9\",\"mfcc_mean10\",\"mfcc_mean11\",\"mfcc_mean12\",\"mfcc_mean13\"]]\n",
    "test_dim = mfcc_data.shape[0]\n",
    "\n",
    "#set up targets (labels)\n",
    "accent_data = pd.read_csv(\"cv-valid-dev-acc-mp3.csv\")\n",
    "targets_raw = np.array(accent_data['accent'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "mfcc_targets = label_encoder.fit_transform(targets_raw)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    mfcc_data,mfcc_targets,test_size=0.20,random_state=42\n",
    ")\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DbKSHznSMzW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=10, input_shape=(13, 13, 1..., padding=\"valid\", activation=\"relu\", filters=64)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=7, padding=\"same\", activation=\"relu\", filters=64)`\n",
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=7, padding=\"same\", activation=\"relu\", filters=64)`\n",
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_34_input to have 4 dimensions, but got array with shape (1080, 13, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-47f639fd2b48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m model.compile(loss='categorical_crossentropy',\n\u001b[1;32m     46\u001b[0m               optimizer='adam',metrics=[\"accuracy\"])\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_34_input to have 4 dimensions, but got array with shape (1080, 13, 1)"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Reshape((X_train.shape[1], X_train.shape[1], 1)))\n",
    "\n",
    "#layer 1\n",
    "#add a Convolution2D which will learn nb_filter mfcc groups:\n",
    "model.add(Convolution2D(nb_filter=nb_filter,\n",
    "                        kernel_size=filter_length_1,\n",
    "                        input_shape=(X_train.shape[1], X_train.shape[1],1),\n",
    "                        padding='valid', activation='relu'))\n",
    "\n",
    "#batch normalization to keep weights in [0,1] range:\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#layer2\n",
    "model.add(Convolution2D(nb_filter=nb_filter,\n",
    "                        kernel_size=filter_length_2,\n",
    "                        padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#standard maxpooling to halve the output of previous layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#layer3\n",
    "model.add(Convolution2D(nb_filter=nb_filter,\n",
    "                        kernel_size=filter_length_2,\n",
    "                        padding='same', activation='relu'\n",
    "                        ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Dropout reduces overfitting\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "#flatten the output of the convolutional layers\n",
    "#so that we can add a vanilla dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#project onto a single unit output layer\n",
    "#and squash with a softmax into 0-1 probability space\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "#fit model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)\n",
    "model.summary()\n",
    "\n",
    "#print report of recall, precision, f1 score\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNpCFay28L/q95YygTjI55p",
   "collapsed_sections": [],
   "name": "cnn_2d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
