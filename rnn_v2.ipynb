{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXRCzGNSVHs6"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFeecLVdVTVz"
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "\n",
    "batch_size = 50\n",
    "hidden_units = 10\n",
    "nb_classes = 16\n",
    "num_lstm_units = 350 #or 64?\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZVdJK54Vc1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 train sequences\n",
      "270 test sequences\n",
      "X_train shape: (1080, 13, 1)\n",
      "X_test shape: (270, 13, 1)\n",
      "y_train shape: (1080,)\n",
      "y_test shape: (270,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_filename = \"mfccs_dev_22050.csv\"\n",
    "dataset = pd.read_csv(mfcc_filename)\n",
    "df = pd.DataFrame(dataset)\n",
    "mfcc_data = df[[\"mfcc_mean1\",\"mfcc_mean2\",\"mfcc_mean3\",\"mfcc_mean4\",\"mfcc_mean5\",\"mfcc_mean6\",\"mfcc_mean7\",\"mfcc_mean8\",\"mfcc_mean9\",\"mfcc_mean10\",\"mfcc_mean11\",\"mfcc_mean12\",\"mfcc_mean13\"]]\n",
    "test_dim = mfcc_data.shape[0]\n",
    "\n",
    "#set up targets (labels)\n",
    "accent_data = pd.read_csv(\"cv-valid-dev-acc-mp3.csv\")\n",
    "targets_raw = np.array(accent_data['accent'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "mfcc_targets = label_encoder.fit_transform(targets_raw)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    mfcc_data,mfcc_targets,test_size=0.20,random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXrZ_XBlW7rK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 13, 350)           492800    \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4550)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4550)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                72816     \n",
      "=================================================================\n",
      "Total params: 565,616\n",
      "Trainable params: 565,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1080 samples, validate on 270 samples\n",
      "Epoch 1/30\n",
      "1080/1080 [==============================] - 4s 3ms/step - loss: 1.8153 - accuracy: 0.4278 - val_loss: 1.5008 - val_accuracy: 0.4778\n",
      "Epoch 2/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.6268 - accuracy: 0.4611 - val_loss: 1.5305 - val_accuracy: 0.4852\n",
      "Epoch 3/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.5849 - accuracy: 0.4639 - val_loss: 1.5138 - val_accuracy: 0.4556\n",
      "Epoch 4/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.5562 - accuracy: 0.4676 - val_loss: 1.4571 - val_accuracy: 0.4593\n",
      "Epoch 5/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.5209 - accuracy: 0.4861 - val_loss: 1.4657 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.5033 - accuracy: 0.4787 - val_loss: 1.4565 - val_accuracy: 0.4667\n",
      "Epoch 7/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.4681 - accuracy: 0.4843 - val_loss: 1.4484 - val_accuracy: 0.5074\n",
      "Epoch 8/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.4522 - accuracy: 0.4741 - val_loss: 1.4714 - val_accuracy: 0.4370\n",
      "Epoch 9/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.4276 - accuracy: 0.4954 - val_loss: 1.4147 - val_accuracy: 0.5148\n",
      "Epoch 10/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.3838 - accuracy: 0.4926 - val_loss: 1.4264 - val_accuracy: 0.5111\n",
      "Epoch 11/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.3744 - accuracy: 0.5120 - val_loss: 1.4281 - val_accuracy: 0.5296\n",
      "Epoch 12/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.3424 - accuracy: 0.5204 - val_loss: 1.4075 - val_accuracy: 0.4926\n",
      "Epoch 13/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.2969 - accuracy: 0.5324 - val_loss: 1.4105 - val_accuracy: 0.5222\n",
      "Epoch 14/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.2742 - accuracy: 0.5306 - val_loss: 1.3970 - val_accuracy: 0.5259\n",
      "Epoch 15/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.2426 - accuracy: 0.5231 - val_loss: 1.4056 - val_accuracy: 0.5111\n",
      "Epoch 16/30\n",
      "1080/1080 [==============================] - 3s 2ms/step - loss: 1.2098 - accuracy: 0.5528 - val_loss: 1.3845 - val_accuracy: 0.5444\n",
      "Epoch 17/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.1737 - accuracy: 0.5741 - val_loss: 1.4526 - val_accuracy: 0.5148\n",
      "Epoch 18/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.1197 - accuracy: 0.5852 - val_loss: 1.4725 - val_accuracy: 0.5296\n",
      "Epoch 19/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.0823 - accuracy: 0.6000 - val_loss: 1.4812 - val_accuracy: 0.5074\n",
      "Epoch 20/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 1.0159 - accuracy: 0.6185 - val_loss: 1.4782 - val_accuracy: 0.5074\n",
      "Epoch 21/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.9442 - accuracy: 0.6620 - val_loss: 1.4719 - val_accuracy: 0.5333\n",
      "Epoch 22/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.8942 - accuracy: 0.6769 - val_loss: 1.4395 - val_accuracy: 0.5593\n",
      "Epoch 23/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.8141 - accuracy: 0.7093 - val_loss: 1.4746 - val_accuracy: 0.5481\n",
      "Epoch 24/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.7510 - accuracy: 0.7231 - val_loss: 1.5723 - val_accuracy: 0.4889\n",
      "Epoch 25/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.6546 - accuracy: 0.7620 - val_loss: 1.5529 - val_accuracy: 0.5370\n",
      "Epoch 26/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.5882 - accuracy: 0.7778 - val_loss: 1.6209 - val_accuracy: 0.4815\n",
      "Epoch 27/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.8194 - val_loss: 1.6674 - val_accuracy: 0.5222\n",
      "Epoch 28/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.4703 - accuracy: 0.8343 - val_loss: 1.7142 - val_accuracy: 0.5259\n",
      "Epoch 29/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.3854 - accuracy: 0.8870 - val_loss: 1.8335 - val_accuracy: 0.5037\n",
      "Epoch 30/30\n",
      "1080/1080 [==============================] - 2s 2ms/step - loss: 0.3339 - accuracy: 0.8972 - val_loss: 1.8212 - val_accuracy: 0.5111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.73      0.30      0.42        27\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.12      0.30      0.18        10\n",
      "           4       0.49      0.49      0.49        72\n",
      "           6       0.27      0.21      0.24        19\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.50      0.50      0.50         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.64      0.67      0.66       130\n",
      "          15       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       270\n",
      "   macro avg       0.20      0.18      0.18       270\n",
      "weighted avg       0.54      0.51      0.51       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(LSTM(num_lstm_units, return_sequences=True, stateful=False,\n",
    "#                batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(LSTM(num_lstm_units, return_sequences=True, stateful=False))\n",
    "# model.add(LSTM(num_lstm_units, stateful=False))\n",
    "model.add(LSTM(num_lstm_units,return_sequences=True,input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "# We flatten the output of the conv layer,\n",
    "# so that we can add a vanilla dense layer:\n",
    "model.add(Flatten())\n",
    "\n",
    "# add dropout to control for overfitting\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "# squash output onto number of classes in probability space\n",
    "model.add(Dense(nb_classes, activation='softmax',\n",
    "               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "               activity_regularizer=regularizers.l2(1e-5)))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                   validation_data=(X_test, Y_test), verbose = 1)\n",
    "\n",
    "y_pred = model.predict_classes(X_test, batch_size=batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cbook' has no attribute '_classproperty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-73525fa20d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  \"Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m     \"\"\"\n\u001b[1;32m   1567\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mrenders\u001b[0m \u001b[0minto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mFigureCanvasBase\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1612\u001b[0m                          'Tagged Image File Format')\n\u001b[1;32m   1613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msupports_blit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m         return (hasattr(cls, \"copy_from_bbox\")\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cbook' has no attribute '_classproperty'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import History \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model acuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPmNYEa0ezyBGSxSLwDM8NG",
   "collapsed_sections": [],
   "name": "rnn_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
