{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Nhau6hODx_H"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cplzftzzROem"
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "\n",
    "nb_filter = 64\n",
    "filter_length_1 = 10\n",
    "filter_length_2 = 7\n",
    "hidden_dims = 10\n",
    "batch_size = 64\n",
    "nb_epoch = 30\n",
    "nb_classes = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YosiMd03RqAE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 train sequences\n",
      "270 test sequences\n",
      "X_train shape: (1080, 13, 1)\n",
      "X_test shape: (270, 13, 1)\n",
      "y_train shape: (1080,)\n",
      "y_test shape: (270,)\n"
     ]
    }
   ],
   "source": [
    "# #load the sequential MFCC data\n",
    "# with open(os.path.join(proj_dir, 'seq_mfcc.pickle'), 'rb') as jar:\n",
    "#   mfcc_data = pickle.load(jar)\n",
    "\n",
    "mfcc_filename = \"mfccs_dev_22050.csv\"\n",
    "dataset = pd.read_csv(mfcc_filename)\n",
    "df = pd.DataFrame(dataset)\n",
    "mfcc_data = df[[\"mfcc_mean1\",\"mfcc_mean2\",\"mfcc_mean3\",\"mfcc_mean4\",\"mfcc_mean5\",\"mfcc_mean6\",\"mfcc_mean7\",\"mfcc_mean8\",\"mfcc_mean9\",\"mfcc_mean10\",\"mfcc_mean11\",\"mfcc_mean12\",\"mfcc_mean13\"]]\n",
    "test_dim = mfcc_data.shape[0]\n",
    "\n",
    "#set up targets (labels)\n",
    "accent_data = pd.read_csv(\"cv-valid-dev-acc-mp3.csv\")\n",
    "targets_raw = np.array(accent_data['accent'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "mfcc_targets = label_encoder.fit_transform(targets_raw)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    mfcc_data,mfcc_targets,test_size=0.20,random_state=42\n",
    ")\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DbKSHznSMzW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_161 (Conv1D)          (None, 4, 64)             704       \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 4, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 4, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 2, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 2, 64)             28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 59,728\n",
      "Trainable params: 59,472\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 2.6628 - accuracy: 0.2046\n",
      "Epoch 2/30\n",
      "1080/1080 [==============================] - 0s 159us/step - loss: 1.8126 - accuracy: 0.4426\n",
      "Epoch 3/30\n",
      "1080/1080 [==============================] - 0s 204us/step - loss: 1.6358 - accuracy: 0.4833\n",
      "Epoch 4/30\n",
      "1080/1080 [==============================] - 0s 144us/step - loss: 1.5313 - accuracy: 0.4852\n",
      "Epoch 5/30\n",
      "1080/1080 [==============================] - 0s 135us/step - loss: 1.4742 - accuracy: 0.5019\n",
      "Epoch 6/30\n",
      "1080/1080 [==============================] - 0s 131us/step - loss: 1.4075 - accuracy: 0.5111\n",
      "Epoch 7/30\n",
      "1080/1080 [==============================] - 0s 161us/step - loss: 1.3668 - accuracy: 0.5426\n",
      "Epoch 8/30\n",
      "1080/1080 [==============================] - 0s 165us/step - loss: 1.3295 - accuracy: 0.5407\n",
      "Epoch 9/30\n",
      "1080/1080 [==============================] - 0s 136us/step - loss: 1.2665 - accuracy: 0.5454\n",
      "Epoch 10/30\n",
      "1080/1080 [==============================] - 0s 159us/step - loss: 1.2016 - accuracy: 0.5676\n",
      "Epoch 11/30\n",
      "1080/1080 [==============================] - 0s 171us/step - loss: 1.1655 - accuracy: 0.5870\n",
      "Epoch 12/30\n",
      "1080/1080 [==============================] - 0s 161us/step - loss: 1.1081 - accuracy: 0.6130\n",
      "Epoch 13/30\n",
      "1080/1080 [==============================] - 0s 128us/step - loss: 1.0547 - accuracy: 0.6204\n",
      "Epoch 14/30\n",
      "1080/1080 [==============================] - 0s 147us/step - loss: 1.0177 - accuracy: 0.6315\n",
      "Epoch 15/30\n",
      "1080/1080 [==============================] - 0s 167us/step - loss: 0.9500 - accuracy: 0.6593\n",
      "Epoch 16/30\n",
      "1080/1080 [==============================] - 0s 137us/step - loss: 0.9356 - accuracy: 0.6806\n",
      "Epoch 17/30\n",
      "1080/1080 [==============================] - 0s 132us/step - loss: 0.8912 - accuracy: 0.6981\n",
      "Epoch 18/30\n",
      "1080/1080 [==============================] - 0s 126us/step - loss: 0.8527 - accuracy: 0.7028\n",
      "Epoch 19/30\n",
      "1080/1080 [==============================] - 0s 149us/step - loss: 0.8024 - accuracy: 0.7269\n",
      "Epoch 20/30\n",
      "1080/1080 [==============================] - 0s 159us/step - loss: 0.7757 - accuracy: 0.7222\n",
      "Epoch 21/30\n",
      "1080/1080 [==============================] - 0s 151us/step - loss: 0.7015 - accuracy: 0.7519\n",
      "Epoch 22/30\n",
      "1080/1080 [==============================] - 0s 159us/step - loss: 0.6478 - accuracy: 0.7870\n",
      "Epoch 23/30\n",
      "1080/1080 [==============================] - 0s 168us/step - loss: 0.6017 - accuracy: 0.7972\n",
      "Epoch 24/30\n",
      "1080/1080 [==============================] - 0s 149us/step - loss: 0.6137 - accuracy: 0.7843\n",
      "Epoch 25/30\n",
      "1080/1080 [==============================] - 0s 175us/step - loss: 0.5750 - accuracy: 0.8148\n",
      "Epoch 26/30\n",
      "1080/1080 [==============================] - 0s 163us/step - loss: 0.5413 - accuracy: 0.8278\n",
      "Epoch 27/30\n",
      "1080/1080 [==============================] - 0s 166us/step - loss: 0.4883 - accuracy: 0.8324\n",
      "Epoch 28/30\n",
      "1080/1080 [==============================] - 0s 189us/step - loss: 0.4874 - accuracy: 0.8333\n",
      "Epoch 29/30\n",
      "1080/1080 [==============================] - 0s 188us/step - loss: 0.4418 - accuracy: 0.8593\n",
      "Epoch 30/30\n",
      "1080/1080 [==============================] - 0s 174us/step - loss: 0.4272 - accuracy: 0.8676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.58      0.26      0.36        27\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.30      0.30      0.30        10\n",
      "           4       0.49      0.62      0.55        72\n",
      "           6       0.33      0.26      0.29        19\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.50      1.00      0.67         1\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.33      0.50      0.40         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.62      0.63      0.62       130\n",
      "\n",
      "    accuracy                           0.53       270\n",
      "   macro avg       0.24      0.28      0.25       270\n",
      "weighted avg       0.53      0.53      0.52       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "model = Sequential()\n",
    "\n",
    "#layer 1\n",
    "#add a Convolution1D which will learn nb_filter mfcc groups:\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_1,\n",
    "                 input_shape=(X_train.shape[1], 1),\n",
    "                 padding='valid', activation='relu'\n",
    "                ))\n",
    "\n",
    "#batch normalization to keep weights in [0,1] range:\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#layer2\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same', activation='relu'\n",
    "                ))\n",
    "\n",
    "#standard maxpooling to halve the output of previous layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#layer3\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same', activation='relu'\n",
    "                ))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "#flatten the output of the convolutional layers\n",
    "#so that we can add a vanilla dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dropout reduces overfitting\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "#project onto a single unit output layer\n",
    "#and squash with a softmax into 0-1 probability space\n",
    "model.add(Dense(nb_classes,activation='softmax',\n",
    "               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "               activity_regularizer=regularizers.l2(1e-5)))\n",
    "\n",
    "#fit model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "model.fit(X_train,Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
    "\n",
    "#print report of recall, precision, f1 score\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increased epoch from 10 to 30\n",
    "#decreased nb_filters from 512 to 64\n",
    "#increased dropout rate from 0.1 to 0.25 (accuracy converges to 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'History' has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-361fc864b03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#  \"Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'History' has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import History \n",
    "\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cnn_1d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
