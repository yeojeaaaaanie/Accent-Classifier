{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG99blVGJr0L"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-9a0b7975ab94>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-9a0b7975ab94>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    import pandas-profiling\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Script to determine the better performing ANN\n",
    "# Check fitting\n",
    "\n",
    "# fn to remove tf warnings when creating a keras model\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "from tensorflow import keras\n",
    "\n",
    "# eager execution enabled to execute operations immediately \n",
    "# without requiring a Session.run()\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import codecs\n",
    "import h5py\n",
    "\n",
    "# importing py files\n",
    "from functions import sigmoid, sigmoid_backward, relu, relu_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47Z57wkRhh8R"
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "batch_size = 50\n",
    "hidden_units = 10\n",
    "nb_classes = 16\n",
    "num_lstm_units = 350 #or 64?\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHWtDxORgspK"
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "mfcc_filename = \"mfccs_dev_22050.csv\"\n",
    "dataset = pd.read_csv(mfcc_filename)\n",
    "df = pd.DataFrame(dataset)\n",
    "mfcc_data = df[[\"mfcc_mean1\",\"mfcc_mean2\",\"mfcc_mean3\",\"mfcc_mean4\",\"mfcc_mean5\",\"mfcc_mean6\",\"mfcc_mean7\",\"mfcc_mean8\",\"mfcc_mean9\",\"mfcc_mean10\",\"mfcc_mean11\",\"mfcc_mean12\",\"mfcc_mean13\"]]\n",
    "test_dim = mfcc_data.shape[0]\n",
    "\n",
    "#set up targets (labels)\n",
    "accent_data = pd.read_csv(\"cv-valid-dev-acc-mp3.csv\")\n",
    "targets_raw = np.array(accent_data['accent'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "mfcc_targets = label_encoder.fit_transform(targets_raw)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    mfcc_data,mfcc_targets,test_size=0.20,random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9kiLibcgyP9"
   },
   "outputs": [],
   "source": [
    "# generate the training and test samples \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feedforward neural network\n",
    "# with softmax activation\n",
    "ff_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(4, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.softmax, input_shape=(X_train.shape[1],X_train.shape[2])),\n",
    "    keras.layers.Dense(3, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# define loss fn as the mean squared logarithmic error\n",
    "# optimizaation fn is Adam\n",
    "# The metrics are: mae->mean absolute error\n",
    "#                  mse->mean squared error\n",
    "#                  mape->mean absolute percentage error\n",
    "#                  msle->mean squared logarithmic error\n",
    "ff_model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy', 'mae', 'mse', 'mape'])\n",
    "\n",
    "# epochs = 1000 gives the least mape in the range of 1 to 1000\n",
    "# the greater the batch_size the greater the mape\n",
    "ff_model_history = l2_model.fit(X_train, Y_train,\n",
    "                               epochs=num_epochs,\n",
    "                               batch_size=batch_size,\n",
    "                               validation_data=(X_test, Y_test),\n",
    "                               verbose=2)\n",
    "\n",
    "# predict the storage modulus using the test dataset\n",
    "y_pred = lff_model.predict_classes(X_test, batch_size = batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Curc7GfkjUAT"
   },
   "outputs": [],
   "source": [
    "# generate the training and test samples \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feedforward neural network\n",
    "# with ReLU activation\n",
    "ff_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(4, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.softmax, input_shape=(X_train.shape[1],X_train.shape[2])),\n",
    "    keras.layers.Dense(3, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# define loss fn as the mean squared logarithmic error\n",
    "# optimizaation fn is Adam\n",
    "# The metrics are: mae->mean absolute error\n",
    "#                  mse->mean squared error\n",
    "#                  mape->mean absolute percentage error\n",
    "#                  msle->mean squared logarithmic error\n",
    "ff_model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy', 'mae', 'mse', 'mape'])\n",
    "\n",
    "# epochs = 1000 gives the least mape in the range of 1 to 1000\n",
    "# the greater the batch_size the greater the mape\n",
    "ff_model_history = l2_model.fit(X_train, Y_train,\n",
    "                               epochs=num_epochs,\n",
    "                               batch_size=batch_size,\n",
    "                               validation_data=(X_test, Y_test),\n",
    "                               verbose=2)\n",
    "\n",
    "# predict the storage modulus using the test dataset\n",
    "y_pred = lff_model.predict_classes(X_test, batch_size = batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpQ/+r7Si9aQY9AY18pNgJ",
   "name": "feedforward_neural_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
