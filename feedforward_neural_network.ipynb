{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG99blVGJr0L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Script to determine the better performing ANN\n",
    "# Check fitting\n",
    "\n",
    "# fn to remove tf warnings when creating a keras model\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from math import floor, ceil\n",
    "# from pylab import rcParams\n",
    "from tensorflow import keras\n",
    "\n",
    "# eager execution enabled to execute operations immediately \n",
    "# without requiring a Session.run()\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "import codecs\n",
    "import h5py\n",
    "\n",
    "# importing py files\n",
    "# from functions import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "# import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47Z57wkRhh8R"
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "batch_size = 50\n",
    "hidden_units = 10\n",
    "nb_classes = 16\n",
    "num_lstm_units = 350 #or 64?\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHWtDxORgspK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 train sequences\n",
      "270 test sequences\n",
      "X_train shape: (1080, 13)\n",
      "X_test shape: (270, 13)\n",
      "y_train shape: (1080,)\n",
      "y_test shape: (270,)\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "mfcc_filename = \"mfccs_dev_22050.csv\"\n",
    "dataset = pd.read_csv(mfcc_filename)\n",
    "df = pd.DataFrame(dataset)\n",
    "mfcc_data = df[[\"mfcc_mean1\",\"mfcc_mean2\",\"mfcc_mean3\",\"mfcc_mean4\",\"mfcc_mean5\",\"mfcc_mean6\",\"mfcc_mean7\",\"mfcc_mean8\",\"mfcc_mean9\",\"mfcc_mean10\",\"mfcc_mean11\",\"mfcc_mean12\",\"mfcc_mean13\"]]\n",
    "test_dim = mfcc_data.shape[0]\n",
    "\n",
    "#set up targets (labels)\n",
    "accent_data = pd.read_csv(\"cv-valid-dev-acc-mp3.csv\")\n",
    "targets_raw = np.array(accent_data['accent'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "mfcc_targets = label_encoder.fit_transform(targets_raw)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    mfcc_data,mfcc_targets,test_size=0.20,random_state=42\n",
    ")\n",
    "\n",
    "# X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "# X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9kiLibcgyP9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 8.6878 - accuracy: 0.0037 - mae: 0.2219 - mse: 0.1012 - mape: 157875472.0000 - val_loss: 8.1378 - val_accuracy: 0.0074 - val_mae: 0.2260 - val_mse: 0.1033 - val_mape: 161286112.0000\n",
      "Epoch 2/100\n",
      " - 0s - loss: 8.8460 - accuracy: 0.0037 - mae: 0.2228 - mse: 0.1017 - mape: 158516352.0000 - val_loss: 8.4370 - val_accuracy: 0.0074 - val_mae: 0.2260 - val_mse: 0.1035 - val_mape: 161175696.0000\n",
      "Epoch 3/100\n",
      " - 0s - loss: 8.7813 - accuracy: 0.0037 - mae: 0.2230 - mse: 0.1019 - mape: 158585344.0000 - val_loss: 8.0751 - val_accuracy: 0.0074 - val_mae: 0.2265 - val_mse: 0.1038 - val_mape: 161557488.0000\n",
      "Epoch 4/100\n",
      " - 0s - loss: 8.9253 - accuracy: 0.0037 - mae: 0.2231 - mse: 0.1019 - mape: 158641488.0000 - val_loss: 8.3675 - val_accuracy: 0.0074 - val_mae: 0.2260 - val_mse: 0.1038 - val_mape: 160935520.0000\n",
      "Epoch 5/100\n",
      " - 0s - loss: 8.9960 - accuracy: 0.0046 - mae: 0.2229 - mse: 0.1019 - mape: 158381696.0000 - val_loss: 8.8005 - val_accuracy: 0.0074 - val_mae: 0.2258 - val_mse: 0.1038 - val_mape: 160749888.0000\n",
      "Epoch 6/100\n",
      " - 0s - loss: 8.8230 - accuracy: 0.0037 - mae: 0.2224 - mse: 0.1021 - mape: 157725120.0000 - val_loss: 8.8436 - val_accuracy: 0.0074 - val_mae: 0.2242 - val_mse: 0.1040 - val_mape: 158691648.0000\n",
      "Epoch 7/100\n",
      " - 0s - loss: 9.3155 - accuracy: 0.0037 - mae: 0.2210 - mse: 0.1021 - mape: 156041504.0000 - val_loss: 8.6166 - val_accuracy: 0.0074 - val_mae: 0.2240 - val_mse: 0.1042 - val_mape: 158258640.0000\n",
      "Epoch 8/100\n",
      " - 0s - loss: 9.4620 - accuracy: 0.0037 - mae: 0.2205 - mse: 0.1022 - mape: 155327472.0000 - val_loss: 9.6819 - val_accuracy: 0.0074 - val_mae: 0.2226 - val_mse: 0.1041 - val_mape: 156627936.0000\n",
      "Epoch 9/100\n",
      " - 0s - loss: 9.2508 - accuracy: 0.0037 - mae: 0.2186 - mse: 0.1023 - mape: 153114560.0000 - val_loss: 8.5252 - val_accuracy: 0.0074 - val_mae: 0.2197 - val_mse: 0.1043 - val_mape: 153137104.0000\n",
      "Epoch 10/100\n",
      " - 0s - loss: 4.6006 - accuracy: 0.0037 - mae: 0.2171 - mse: 0.1034 - mape: 150543552.0000 - val_loss: 1.1079 - val_accuracy: 0.0074 - val_mae: 0.2192 - val_mse: 0.1066 - val_mape: 150970032.0000\n",
      "Epoch 11/100\n",
      " - 0s - loss: 11.7141 - accuracy: 0.0037 - mae: 0.2167 - mse: 0.1045 - mape: 149332768.0000 - val_loss: 15.3675 - val_accuracy: 0.0074 - val_mae: 0.2185 - val_mse: 0.1066 - val_mape: 150189888.0000\n",
      "Epoch 12/100\n",
      " - 0s - loss: 14.4673 - accuracy: 0.0037 - mae: 0.2164 - mse: 0.1046 - mape: 148927472.0000 - val_loss: 15.1600 - val_accuracy: 0.0074 - val_mae: 0.2188 - val_mse: 0.1068 - val_mape: 150387056.0000\n",
      "Epoch 13/100\n",
      " - 0s - loss: 14.0064 - accuracy: 0.0037 - mae: 0.2176 - mse: 0.1048 - mape: 150058048.0000 - val_loss: 15.1176 - val_accuracy: 0.0074 - val_mae: 0.2202 - val_mse: 0.1073 - val_mape: 151543248.0000\n",
      "Epoch 14/100\n",
      " - 0s - loss: 13.7722 - accuracy: 0.0037 - mae: 0.2184 - mse: 0.1052 - mape: 150670800.0000 - val_loss: 14.4540 - val_accuracy: 0.0074 - val_mae: 0.2206 - val_mse: 0.1076 - val_mape: 151706736.0000\n",
      "Epoch 15/100\n",
      " - 0s - loss: 9.4703 - accuracy: 0.0037 - mae: 0.2186 - mse: 0.1054 - mape: 150791760.0000 - val_loss: 4.9025 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1077 - val_mape: 151766096.0000\n",
      "Epoch 16/100\n",
      " - 0s - loss: 5.4848 - accuracy: 0.0037 - mae: 0.2187 - mse: 0.1055 - mape: 150856128.0000 - val_loss: 3.7681 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151814768.0000\n",
      "Epoch 17/100\n",
      " - 0s - loss: 4.8726 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1056 - mape: 150908400.0000 - val_loss: 3.7084 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1079 - val_mape: 151844832.0000\n",
      "Epoch 18/100\n",
      " - 0s - loss: 4.9023 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150923424.0000 - val_loss: 3.7680 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151845008.0000\n",
      "Epoch 19/100\n",
      " - 0s - loss: 4.9172 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150918544.0000 - val_loss: 3.7680 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151838576.0000\n",
      "Epoch 20/100\n",
      " - 0s - loss: 4.9171 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150909616.0000 - val_loss: 3.7679 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151831184.0000\n",
      "Epoch 21/100\n",
      " - 0s - loss: 4.9320 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150901232.0000 - val_loss: 3.7679 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151823296.0000\n",
      "Epoch 22/100\n",
      " - 0s - loss: 4.9319 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150891664.0000 - val_loss: 3.7678 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151814880.0000\n",
      "Epoch 23/100\n",
      " - 0s - loss: 4.9319 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150882784.0000 - val_loss: 3.7678 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151805936.0000\n",
      "Epoch 24/100\n",
      " - 0s - loss: 4.9468 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150873376.0000 - val_loss: 3.7677 - val_accuracy: 0.0074 - val_mae: 0.2208 - val_mse: 0.1078 - val_mape: 151796304.0000\n",
      "Epoch 25/100\n",
      " - 0s - loss: 4.9467 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150864272.0000 - val_loss: 3.7677 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151785984.0000\n",
      "Epoch 26/100\n",
      " - 0s - loss: 4.9318 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150852720.0000 - val_loss: 3.7677 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151775472.0000\n",
      "Epoch 27/100\n",
      " - 0s - loss: 4.9317 - accuracy: 0.0037 - mae: 0.2188 - mse: 0.1055 - mape: 150841872.0000 - val_loss: 3.7079 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151767440.0000\n",
      "Epoch 28/100\n",
      " - 0s - loss: 4.9317 - accuracy: 0.0037 - mae: 0.2187 - mse: 0.1055 - mape: 150830544.0000 - val_loss: 3.7079 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151759024.0000\n",
      "Epoch 29/100\n",
      " - 0s - loss: 4.9317 - accuracy: 0.0037 - mae: 0.2187 - mse: 0.1055 - mape: 150819184.0000 - val_loss: 3.7079 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151749696.0000\n",
      "Epoch 30/100\n",
      " - 0s - loss: 4.9466 - accuracy: 0.0037 - mae: 0.2187 - mse: 0.1055 - mape: 150808048.0000 - val_loss: 3.7079 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151739216.0000\n",
      "Epoch 31/100\n",
      " - 0s - loss: 4.9465 - accuracy: 0.0037 - mae: 0.2187 - mse: 0.1055 - mape: 150796320.0000 - val_loss: 3.7078 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151727392.0000\n",
      "Epoch 32/100\n",
      " - 0s - loss: 4.9465 - accuracy: 0.0037 - mae: 0.2187 - mse: 0.1055 - mape: 150784320.0000 - val_loss: 3.7078 - val_accuracy: 0.0074 - val_mae: 0.2207 - val_mse: 0.1078 - val_mape: 151714560.0000\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-70b842ae0492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m              verbose=2)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# predict the storage modulus using the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# feedforward neural network\n",
    "\n",
    "# with softmax activation\n",
    "ff_model = Sequential()\n",
    "\n",
    "ff_model.add(Dense(4, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation='softmax', input_dim=13)) \n",
    "ff_model.add(Dense(3, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation='softmax'))\n",
    "ff_model.add(Dense(nb_classes))\n",
    "\n",
    "# define loss fn as the mean squared logarithmic error\n",
    "# optimizaation fn is Adam\n",
    "# The metrics are: mae->mean absolute error\n",
    "#                  mse->mean squared error\n",
    "#                  mape->mean absolute percentage error\n",
    "#                  msle->mean squared logarithmic error\n",
    "ff_model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy', 'mae', 'mse', 'mape'])\n",
    "\n",
    "# epochs = 1000 gives the least mape in the range of 1 to 1000\n",
    "# the greater the batch_size the greater the mape\n",
    "# ff_model_history = ff_model.fit(X_train, Y_train,\n",
    "#                                epochs=num_epochs,\n",
    "#                                batch_size=batch_size,\n",
    "# #                                validation_data=(X_test, Y_test),\n",
    "#                                verbose=2)\n",
    "ff_model.fit(X_train, Y_train,\n",
    "             epochs=num_epochs, batch_size=batch_size,\n",
    "             validation_data=(X_test, Y_test),\n",
    "             verbose=2)\n",
    "\n",
    "# predict the storage modulus using the test dataset\n",
    "y_pred = ff_model.predict_classes(X_test, batch_size = batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Curc7GfkjUAT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 270 samples\n",
      "Epoch 1/100\n",
      "1080/1080 - 1s - loss: 10.6903 - accuracy: 0.0324 - mae: 0.2136 - mse: 0.0982 - mape: 152006832.0000 - val_loss: 9.3815 - val_accuracy: 0.0815 - val_mae: 0.2147 - val_mse: 0.0989 - val_mape: 152573584.0000\n",
      "Epoch 2/100\n",
      "1080/1080 - 0s - loss: 8.7258 - accuracy: 0.0602 - mae: 0.2161 - mse: 0.0998 - mape: 153467568.0000 - val_loss: 9.3212 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0998 - val_mape: 153134960.0000\n",
      "Epoch 3/100\n",
      "1080/1080 - 0s - loss: 8.7398 - accuracy: 0.0611 - mae: 0.2165 - mse: 0.1002 - mape: 153663024.0000 - val_loss: 9.5597 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0999 - val_mape: 153144416.0000\n",
      "Epoch 4/100\n",
      "1080/1080 - 0s - loss: 8.8438 - accuracy: 0.0620 - mae: 0.2165 - mse: 0.1002 - mape: 153643552.0000 - val_loss: 9.4998 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0998 - val_mape: 153115296.0000\n",
      "Epoch 5/100\n",
      "1080/1080 - 0s - loss: 9.3658 - accuracy: 0.0620 - mae: 0.2164 - mse: 0.1001 - mape: 153598864.0000 - val_loss: 11.3502 - val_accuracy: 0.0889 - val_mae: 0.2157 - val_mse: 0.0997 - val_mape: 153067680.0000\n",
      "Epoch 6/100\n",
      "1080/1080 - 0s - loss: 11.4997 - accuracy: 0.0620 - mae: 0.2163 - mse: 0.1000 - mape: 153573936.0000 - val_loss: 11.3500 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0997 - val_mape: 153137280.0000\n",
      "Epoch 7/100\n",
      "1080/1080 - 0s - loss: 9.8428 - accuracy: 0.0620 - mae: 0.2165 - mse: 0.1000 - mape: 153643712.0000 - val_loss: 11.3498 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0997 - val_mape: 153136352.0000\n",
      "Epoch 8/100\n",
      "1080/1080 - 0s - loss: 10.7829 - accuracy: 0.0620 - mae: 0.2165 - mse: 0.1000 - mape: 153679376.0000 - val_loss: 9.2602 - val_accuracy: 0.0889 - val_mae: 0.2165 - val_mse: 0.1001 - val_mape: 153616320.0000\n",
      "Epoch 9/100\n",
      "1080/1080 - 0s - loss: 8.5592 - accuracy: 0.0620 - mae: 0.2174 - mse: 0.1005 - mape: 154289472.0000 - val_loss: 9.0213 - val_accuracy: 0.0889 - val_mae: 0.2168 - val_mse: 0.1002 - val_mape: 153892800.0000\n",
      "Epoch 10/100\n",
      "1080/1080 - 0s - loss: 8.6634 - accuracy: 0.0620 - mae: 0.2174 - mse: 0.1004 - mape: 154359088.0000 - val_loss: 9.4390 - val_accuracy: 0.0889 - val_mae: 0.2167 - val_mse: 0.1000 - val_mape: 153847888.0000\n",
      "Epoch 11/100\n",
      "1080/1080 - 0s - loss: 8.7228 - accuracy: 0.0620 - mae: 0.2173 - mse: 0.1003 - mape: 154307280.0000 - val_loss: 9.4986 - val_accuracy: 0.0889 - val_mae: 0.2166 - val_mse: 0.0999 - val_mape: 153769088.0000\n",
      "Epoch 12/100\n",
      "1080/1080 - 0s - loss: 9.0359 - accuracy: 0.0620 - mae: 0.2171 - mse: 0.1001 - mape: 154217296.0000 - val_loss: 9.6179 - val_accuracy: 0.0889 - val_mae: 0.2164 - val_mse: 0.0998 - val_mape: 153693296.0000\n",
      "Epoch 13/100\n",
      "1080/1080 - 0s - loss: 9.2298 - accuracy: 0.0620 - mae: 0.2171 - mse: 0.1001 - mape: 154154160.0000 - val_loss: 9.6775 - val_accuracy: 0.0889 - val_mae: 0.2164 - val_mse: 0.0998 - val_mape: 153639440.0000\n",
      "Epoch 14/100\n",
      "1080/1080 - 0s - loss: 9.2745 - accuracy: 0.0620 - mae: 0.2170 - mse: 0.1001 - mape: 154099232.0000 - val_loss: 9.6773 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0998 - val_mape: 153585824.0000\n",
      "Epoch 15/100\n",
      "1080/1080 - 0s - loss: 9.2743 - accuracy: 0.0620 - mae: 0.2170 - mse: 0.1000 - mape: 154040000.0000 - val_loss: 9.6772 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0998 - val_mape: 153530240.0000\n",
      "Epoch 16/100\n",
      "1080/1080 - 0s - loss: 9.2742 - accuracy: 0.0620 - mae: 0.2169 - mse: 0.1000 - mape: 153975984.0000 - val_loss: 9.6771 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0997 - val_mape: 153472464.0000\n",
      "Epoch 17/100\n",
      "1080/1080 - 0s - loss: 9.2592 - accuracy: 0.0620 - mae: 0.2168 - mse: 0.1000 - mape: 153905040.0000 - val_loss: 9.7367 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0997 - val_mape: 153412464.0000\n",
      "Epoch 18/100\n",
      "1080/1080 - 0s - loss: 9.2143 - accuracy: 0.0620 - mae: 0.2168 - mse: 0.1000 - mape: 153834560.0000 - val_loss: 9.7366 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0997 - val_mape: 153350288.0000\n",
      "Epoch 19/100\n",
      "1080/1080 - 0s - loss: 9.1695 - accuracy: 0.0620 - mae: 0.2167 - mse: 0.0999 - mape: 153756416.0000 - val_loss: 9.7366 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0997 - val_mape: 153286032.0000\n",
      "Epoch 20/100\n",
      "1080/1080 - 0s - loss: 9.1694 - accuracy: 0.0620 - mae: 0.2166 - mse: 0.0999 - mape: 153682240.0000 - val_loss: 9.6768 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0997 - val_mape: 153219840.0000\n",
      "Epoch 21/100\n",
      "1080/1080 - 0s - loss: 9.1842 - accuracy: 0.0630 - mae: 0.2165 - mse: 0.0999 - mape: 153599552.0000 - val_loss: 9.6170 - val_accuracy: 0.0889 - val_mae: 0.2159 - val_mse: 0.0996 - val_mape: 153151488.0000\n",
      "Epoch 22/100\n",
      "1080/1080 - 0s - loss: 9.1543 - accuracy: 0.0630 - mae: 0.2165 - mse: 0.0999 - mape: 153511904.0000 - val_loss: 9.6169 - val_accuracy: 0.0889 - val_mae: 0.2159 - val_mse: 0.0996 - val_mape: 153080816.0000\n",
      "Epoch 23/100\n",
      "1080/1080 - 0s - loss: 9.1094 - accuracy: 0.0630 - mae: 0.2164 - mse: 0.0998 - mape: 153420448.0000 - val_loss: 9.6168 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0996 - val_mape: 153007600.0000\n",
      "Epoch 24/100\n",
      "1080/1080 - 0s - loss: 9.1094 - accuracy: 0.0630 - mae: 0.2163 - mse: 0.0998 - mape: 153322352.0000 - val_loss: 9.6764 - val_accuracy: 0.0889 - val_mae: 0.2157 - val_mse: 0.0996 - val_mape: 152932800.0000\n",
      "Epoch 25/100\n",
      "1080/1080 - 0s - loss: 9.0944 - accuracy: 0.0630 - mae: 0.2162 - mse: 0.0998 - mape: 153231856.0000 - val_loss: 9.6167 - val_accuracy: 0.0889 - val_mae: 0.2156 - val_mse: 0.0995 - val_mape: 152855488.0000\n",
      "Epoch 26/100\n",
      "1080/1080 - 0s - loss: 9.0644 - accuracy: 0.0630 - mae: 0.2161 - mse: 0.0997 - mape: 153134656.0000 - val_loss: 9.6166 - val_accuracy: 0.0889 - val_mae: 0.2156 - val_mse: 0.0995 - val_mape: 152775216.0000\n",
      "Epoch 27/100\n",
      "1080/1080 - 0s - loss: 9.0345 - accuracy: 0.0630 - mae: 0.2160 - mse: 0.0997 - mape: 153031072.0000 - val_loss: 9.6165 - val_accuracy: 0.0889 - val_mae: 0.2155 - val_mse: 0.0995 - val_mape: 152692112.0000\n",
      "Epoch 28/100\n",
      "1080/1080 - 0s - loss: 9.0345 - accuracy: 0.0630 - mae: 0.2159 - mse: 0.0997 - mape: 152932784.0000 - val_loss: 9.6165 - val_accuracy: 0.0889 - val_mae: 0.2154 - val_mse: 0.0994 - val_mape: 152606224.0000\n",
      "Epoch 29/100\n",
      "1080/1080 - 0s - loss: 8.9747 - accuracy: 0.0630 - mae: 0.2158 - mse: 0.0996 - mape: 152831568.0000 - val_loss: 9.5567 - val_accuracy: 0.0889 - val_mae: 0.2153 - val_mse: 0.0994 - val_mape: 152517376.0000\n",
      "Epoch 30/100\n",
      "1080/1080 - 0s - loss: 8.9746 - accuracy: 0.0630 - mae: 0.2157 - mse: 0.0996 - mape: 152734112.0000 - val_loss: 9.5566 - val_accuracy: 0.0889 - val_mae: 0.2152 - val_mse: 0.0994 - val_mape: 152428960.0000\n",
      "Epoch 31/100\n",
      "1080/1080 - 0s - loss: 8.9597 - accuracy: 0.0630 - mae: 0.2156 - mse: 0.0996 - mape: 152634096.0000 - val_loss: 9.6760 - val_accuracy: 0.0889 - val_mae: 0.2152 - val_mse: 0.0994 - val_mape: 152337424.0000\n",
      "Epoch 32/100\n",
      "1080/1080 - 0s - loss: 8.9297 - accuracy: 0.0630 - mae: 0.2155 - mse: 0.0995 - mape: 152530480.0000 - val_loss: 9.6162 - val_accuracy: 0.0889 - val_mae: 0.2151 - val_mse: 0.0993 - val_mape: 152242656.0000\n",
      "Epoch 33/100\n",
      "1080/1080 - 0s - loss: 8.9148 - accuracy: 0.0630 - mae: 0.2154 - mse: 0.0995 - mape: 152427008.0000 - val_loss: 9.6162 - val_accuracy: 0.0889 - val_mae: 0.2150 - val_mse: 0.0993 - val_mape: 152144528.0000\n",
      "Epoch 34/100\n",
      "1080/1080 - 0s - loss: 8.8849 - accuracy: 0.0630 - mae: 0.2153 - mse: 0.0995 - mape: 152319488.0000 - val_loss: 9.5564 - val_accuracy: 0.0889 - val_mae: 0.2149 - val_mse: 0.0993 - val_mape: 152042848.0000\n",
      "Epoch 35/100\n",
      "1080/1080 - 0s - loss: 8.8848 - accuracy: 0.0639 - mae: 0.2152 - mse: 0.0994 - mape: 152208912.0000 - val_loss: 9.5564 - val_accuracy: 0.0889 - val_mae: 0.2148 - val_mse: 0.0992 - val_mape: 151938128.0000\n",
      "Epoch 36/100\n",
      "1080/1080 - 0s - loss: 8.8698 - accuracy: 0.0639 - mae: 0.2151 - mse: 0.0994 - mape: 152099216.0000 - val_loss: 9.4966 - val_accuracy: 0.0889 - val_mae: 0.2147 - val_mse: 0.0992 - val_mape: 151830368.0000\n",
      "Epoch 37/100\n",
      "1080/1080 - 0s - loss: 8.6377 - accuracy: 0.0657 - mae: 0.2155 - mse: 0.0994 - mape: 152281520.0000 - val_loss: 8.8996 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0993 - val_mape: 152610576.0000\n",
      "Epoch 38/100\n",
      "1080/1080 - 0s - loss: 8.2578 - accuracy: 0.0694 - mae: 0.2166 - mse: 0.0995 - mape: 152956912.0000 - val_loss: 8.6010 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0994 - val_mape: 152834256.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "1080/1080 - 0s - loss: 8.1682 - accuracy: 0.0713 - mae: 0.2167 - mse: 0.0995 - mape: 153012816.0000 - val_loss: 8.6010 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0994 - val_mape: 152820048.0000\n",
      "Epoch 40/100\n",
      "1080/1080 - 0s - loss: 8.0786 - accuracy: 0.0713 - mae: 0.2167 - mse: 0.0995 - mape: 152971504.0000 - val_loss: 8.6010 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0993 - val_mape: 152783072.0000\n",
      "Epoch 41/100\n",
      "1080/1080 - 0s - loss: 8.0189 - accuracy: 0.0713 - mae: 0.2166 - mse: 0.0995 - mape: 152907248.0000 - val_loss: 8.6009 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0993 - val_mape: 152741776.0000\n",
      "Epoch 42/100\n",
      "1080/1080 - 0s - loss: 8.0338 - accuracy: 0.0713 - mae: 0.2166 - mse: 0.0995 - mape: 152847376.0000 - val_loss: 8.5412 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0993 - val_mape: 152698432.0000\n",
      "Epoch 43/100\n",
      "1080/1080 - 0s - loss: 8.0188 - accuracy: 0.0713 - mae: 0.2165 - mse: 0.0995 - mape: 152786704.0000 - val_loss: 8.4815 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0993 - val_mape: 152653392.0000\n",
      "Epoch 44/100\n",
      "1080/1080 - 0s - loss: 7.9889 - accuracy: 0.0731 - mae: 0.2164 - mse: 0.0995 - mape: 152728752.0000 - val_loss: 8.4217 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0993 - val_mape: 152606880.0000\n",
      "Epoch 45/100\n",
      "1080/1080 - 0s - loss: 7.9889 - accuracy: 0.0731 - mae: 0.2164 - mse: 0.0994 - mape: 152665536.0000 - val_loss: 8.4217 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0993 - val_mape: 152559152.0000\n",
      "Epoch 46/100\n",
      "1080/1080 - 0s - loss: 7.9889 - accuracy: 0.0731 - mae: 0.2163 - mse: 0.0994 - mape: 152602320.0000 - val_loss: 8.4217 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0993 - val_mape: 152511952.0000\n",
      "Epoch 47/100\n",
      "1080/1080 - 0s - loss: 7.9889 - accuracy: 0.0731 - mae: 0.2163 - mse: 0.0994 - mape: 152540128.0000 - val_loss: 8.4813 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0993 - val_mape: 152464352.0000\n",
      "Epoch 48/100\n",
      "1080/1080 - 0s - loss: 7.9888 - accuracy: 0.0731 - mae: 0.2162 - mse: 0.0994 - mape: 152479312.0000 - val_loss: 8.4813 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0993 - val_mape: 152416496.0000\n",
      "Epoch 49/100\n",
      "1080/1080 - 0s - loss: 10.0635 - accuracy: 0.0731 - mae: 0.2159 - mse: 0.0990 - mape: 152405280.0000 - val_loss: 11.3467 - val_accuracy: 0.0889 - val_mae: 0.2157 - val_mse: 0.0987 - val_mape: 152487920.0000\n",
      "Epoch 50/100\n",
      "1080/1080 - 0s - loss: 9.9141 - accuracy: 0.0731 - mae: 0.2162 - mse: 0.0990 - mape: 152655792.0000 - val_loss: 8.4216 - val_accuracy: 0.0889 - val_mae: 0.2165 - val_mse: 0.0993 - val_mape: 152960416.0000\n",
      "Epoch 51/100\n",
      "1080/1080 - 0s - loss: 5.2875 - accuracy: 0.0731 - mae: 0.2168 - mse: 0.0996 - mape: 153029792.0000 - val_loss: 4.6607 - val_accuracy: 0.0889 - val_mae: 0.2167 - val_mse: 0.0995 - val_mape: 153099872.0000\n",
      "Epoch 52/100\n",
      "1080/1080 - 0s - loss: 7.9889 - accuracy: 0.0731 - mae: 0.2166 - mse: 0.0992 - mape: 152991888.0000 - val_loss: 11.2273 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0988 - val_mape: 152947520.0000\n",
      "Epoch 53/100\n",
      "1080/1080 - 0s - loss: 8.5708 - accuracy: 0.0731 - mae: 0.2167 - mse: 0.0992 - mape: 153113440.0000 - val_loss: 4.6606 - val_accuracy: 0.0889 - val_mae: 0.2170 - val_mse: 0.0995 - val_mape: 153449024.0000\n",
      "Epoch 54/100\n",
      "1080/1080 - 0s - loss: 4.5413 - accuracy: 0.0731 - mae: 0.2172 - mse: 0.0997 - mape: 153425504.0000 - val_loss: 4.6606 - val_accuracy: 0.0889 - val_mae: 0.2170 - val_mse: 0.0995 - val_mape: 153485376.0000\n",
      "Epoch 55/100\n",
      "1080/1080 - 0s - loss: 8.7647 - accuracy: 0.0731 - mae: 0.2169 - mse: 0.0992 - mape: 153318544.0000 - val_loss: 11.0481 - val_accuracy: 0.0889 - val_mae: 0.2166 - val_mse: 0.0988 - val_mape: 153323056.0000\n",
      "Epoch 56/100\n",
      "1080/1080 - 0s - loss: 10.9586 - accuracy: 0.0731 - mae: 0.2166 - mse: 0.0989 - mape: 153230224.0000 - val_loss: 11.2272 - val_accuracy: 0.0889 - val_mae: 0.2165 - val_mse: 0.0988 - val_mape: 153267168.0000\n",
      "Epoch 57/100\n",
      "1080/1080 - 0s - loss: 11.0182 - accuracy: 0.0731 - mae: 0.2166 - mse: 0.0989 - mape: 153177328.0000 - val_loss: 11.2272 - val_accuracy: 0.0889 - val_mae: 0.2164 - val_mse: 0.0988 - val_mape: 153222672.0000\n",
      "Epoch 58/100\n",
      "1080/1080 - 0s - loss: 11.0033 - accuracy: 0.0731 - mae: 0.2165 - mse: 0.0989 - mape: 153129696.0000 - val_loss: 11.2271 - val_accuracy: 0.0889 - val_mae: 0.2164 - val_mse: 0.0988 - val_mape: 153179472.0000\n",
      "Epoch 59/100\n",
      "1080/1080 - 0s - loss: 10.9734 - accuracy: 0.0731 - mae: 0.2165 - mse: 0.0988 - mape: 153083040.0000 - val_loss: 11.1674 - val_accuracy: 0.0889 - val_mae: 0.2164 - val_mse: 0.0987 - val_mape: 153137008.0000\n",
      "Epoch 60/100\n",
      "1080/1080 - 0s - loss: 10.9585 - accuracy: 0.0731 - mae: 0.2165 - mse: 0.0988 - mape: 153037984.0000 - val_loss: 11.1674 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0987 - val_mape: 153094704.0000\n",
      "Epoch 61/100\n",
      "1080/1080 - 0s - loss: 10.9584 - accuracy: 0.0731 - mae: 0.2164 - mse: 0.0988 - mape: 152993280.0000 - val_loss: 11.1674 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0987 - val_mape: 153052512.0000\n",
      "Epoch 62/100\n",
      "1080/1080 - 0s - loss: 10.9435 - accuracy: 0.0741 - mae: 0.2164 - mse: 0.0988 - mape: 152949408.0000 - val_loss: 11.1673 - val_accuracy: 0.0889 - val_mae: 0.2163 - val_mse: 0.0987 - val_mape: 153010512.0000\n",
      "Epoch 63/100\n",
      "1080/1080 - 0s - loss: 10.9435 - accuracy: 0.0741 - mae: 0.2163 - mse: 0.0988 - mape: 152905488.0000 - val_loss: 11.1673 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0987 - val_mape: 152968704.0000\n",
      "Epoch 64/100\n",
      "1080/1080 - 0s - loss: 10.9285 - accuracy: 0.0759 - mae: 0.2163 - mse: 0.0988 - mape: 152861984.0000 - val_loss: 11.1673 - val_accuracy: 0.0889 - val_mae: 0.2162 - val_mse: 0.0987 - val_mape: 152927136.0000\n",
      "Epoch 65/100\n",
      "1080/1080 - 0s - loss: 10.9285 - accuracy: 0.0759 - mae: 0.2163 - mse: 0.0988 - mape: 152818096.0000 - val_loss: 11.1673 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0987 - val_mape: 152885744.0000\n",
      "Epoch 66/100\n",
      "1080/1080 - 0s - loss: 10.9136 - accuracy: 0.0769 - mae: 0.2162 - mse: 0.0988 - mape: 152776704.0000 - val_loss: 11.1673 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0987 - val_mape: 152844672.0000\n",
      "Epoch 67/100\n",
      "1080/1080 - 0s - loss: 10.9135 - accuracy: 0.0769 - mae: 0.2162 - mse: 0.0988 - mape: 152734400.0000 - val_loss: 11.1672 - val_accuracy: 0.0889 - val_mae: 0.2161 - val_mse: 0.0987 - val_mape: 152803840.0000\n",
      "Epoch 68/100\n",
      "1080/1080 - 0s - loss: 10.9135 - accuracy: 0.0769 - mae: 0.2161 - mse: 0.0987 - mape: 152693856.0000 - val_loss: 11.1672 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0987 - val_mape: 152763680.0000\n",
      "Epoch 69/100\n",
      "1080/1080 - 0s - loss: 10.8986 - accuracy: 0.0769 - mae: 0.2161 - mse: 0.0987 - mape: 152652864.0000 - val_loss: 11.1672 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0986 - val_mape: 152724032.0000\n",
      "Epoch 70/100\n",
      "1080/1080 - 0s - loss: 10.8986 - accuracy: 0.0769 - mae: 0.2161 - mse: 0.0987 - mape: 152612848.0000 - val_loss: 11.1672 - val_accuracy: 0.0889 - val_mae: 0.2160 - val_mse: 0.0986 - val_mape: 152684656.0000\n",
      "Epoch 71/100\n",
      "1080/1080 - 0s - loss: 10.8985 - accuracy: 0.0778 - mae: 0.2160 - mse: 0.0987 - mape: 152571840.0000 - val_loss: 11.1672 - val_accuracy: 0.0889 - val_mae: 0.2159 - val_mse: 0.0986 - val_mape: 152645952.0000\n",
      "Epoch 72/100\n",
      "1080/1080 - 0s - loss: 10.8985 - accuracy: 0.0787 - mae: 0.2160 - mse: 0.0987 - mape: 152534192.0000 - val_loss: 11.1671 - val_accuracy: 0.0889 - val_mae: 0.2159 - val_mse: 0.0986 - val_mape: 152607504.0000\n",
      "Epoch 73/100\n",
      "1080/1080 - 0s - loss: 10.8985 - accuracy: 0.0787 - mae: 0.2160 - mse: 0.0987 - mape: 152494592.0000 - val_loss: 11.1671 - val_accuracy: 0.0889 - val_mae: 0.2159 - val_mse: 0.0986 - val_mape: 152569248.0000\n",
      "Epoch 74/100\n",
      "1080/1080 - 0s - loss: 10.8836 - accuracy: 0.0787 - mae: 0.2159 - mse: 0.0987 - mape: 152456592.0000 - val_loss: 11.1671 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0986 - val_mape: 152531168.0000\n",
      "Epoch 75/100\n",
      "1080/1080 - 0s - loss: 10.8985 - accuracy: 0.0796 - mae: 0.2159 - mse: 0.0987 - mape: 152418880.0000 - val_loss: 11.1671 - val_accuracy: 0.0889 - val_mae: 0.2158 - val_mse: 0.0986 - val_mape: 152493280.0000\n",
      "Epoch 76/100\n",
      "1080/1080 - 0s - loss: 10.8835 - accuracy: 0.0796 - mae: 0.2159 - mse: 0.0987 - mape: 152381328.0000 - val_loss: 11.1671 - val_accuracy: 0.0889 - val_mae: 0.2157 - val_mse: 0.0986 - val_mape: 152455504.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "1080/1080 - 0s - loss: 10.8835 - accuracy: 0.0796 - mae: 0.2158 - mse: 0.0987 - mape: 152343616.0000 - val_loss: 11.1671 - val_accuracy: 0.0889 - val_mae: 0.2157 - val_mse: 0.0986 - val_mape: 152417824.0000\n",
      "Epoch 78/100\n",
      "1080/1080 - 0s - loss: 10.8686 - accuracy: 0.0796 - mae: 0.2158 - mse: 0.0987 - mape: 152305904.0000 - val_loss: 11.1670 - val_accuracy: 0.0889 - val_mae: 0.2157 - val_mse: 0.0986 - val_mape: 152380208.0000\n",
      "Epoch 79/100\n",
      "1080/1080 - 0s - loss: 10.8835 - accuracy: 0.0806 - mae: 0.2158 - mse: 0.0986 - mape: 152269376.0000 - val_loss: 11.1670 - val_accuracy: 0.0889 - val_mae: 0.2156 - val_mse: 0.0986 - val_mape: 152342688.0000\n",
      "Epoch 80/100\n",
      "1080/1080 - 0s - loss: 10.8984 - accuracy: 0.0806 - mae: 0.2157 - mse: 0.0986 - mape: 152231856.0000 - val_loss: 11.1670 - val_accuracy: 0.0889 - val_mae: 0.2156 - val_mse: 0.0985 - val_mape: 152305472.0000\n",
      "Epoch 81/100\n",
      "1080/1080 - 0s - loss: 10.8984 - accuracy: 0.0806 - mae: 0.2157 - mse: 0.0986 - mape: 152195040.0000 - val_loss: 11.1670 - val_accuracy: 0.0889 - val_mae: 0.2156 - val_mse: 0.0985 - val_mape: 152268304.0000\n",
      "Epoch 82/100\n",
      "1080/1080 - 0s - loss: 10.8983 - accuracy: 0.0815 - mae: 0.2157 - mse: 0.0986 - mape: 152158144.0000 - val_loss: 11.1670 - val_accuracy: 0.0889 - val_mae: 0.2155 - val_mse: 0.0985 - val_mape: 152231104.0000\n",
      "Epoch 83/100\n",
      "1080/1080 - 0s - loss: 10.8983 - accuracy: 0.0815 - mae: 0.2156 - mse: 0.0986 - mape: 152122608.0000 - val_loss: 11.1669 - val_accuracy: 0.0889 - val_mae: 0.2155 - val_mse: 0.0985 - val_mape: 152193856.0000\n",
      "Epoch 84/100\n",
      "1080/1080 - 0s - loss: 10.8983 - accuracy: 0.0815 - mae: 0.2156 - mse: 0.0986 - mape: 152085536.0000 - val_loss: 11.1669 - val_accuracy: 0.0926 - val_mae: 0.2155 - val_mse: 0.0985 - val_mape: 152156592.0000\n",
      "Epoch 85/100\n",
      "1080/1080 - 0s - loss: 10.8983 - accuracy: 0.0815 - mae: 0.2156 - mse: 0.0986 - mape: 152048928.0000 - val_loss: 11.1669 - val_accuracy: 0.0926 - val_mae: 0.2154 - val_mse: 0.0985 - val_mape: 152119200.0000\n",
      "Epoch 86/100\n",
      "1080/1080 - 0s - loss: 10.8983 - accuracy: 0.0815 - mae: 0.2155 - mse: 0.0986 - mape: 152011968.0000 - val_loss: 11.1669 - val_accuracy: 0.0926 - val_mae: 0.2154 - val_mse: 0.0985 - val_mape: 152081744.0000\n",
      "Epoch 87/100\n",
      "1080/1080 - 0s - loss: 10.8983 - accuracy: 0.0815 - mae: 0.2155 - mse: 0.0986 - mape: 151976832.0000 - val_loss: 11.1072 - val_accuracy: 0.0926 - val_mae: 0.2154 - val_mse: 0.0985 - val_mape: 152044640.0000\n",
      "Epoch 88/100\n",
      "1080/1080 - 0s - loss: 10.8982 - accuracy: 0.0815 - mae: 0.2155 - mse: 0.0986 - mape: 151939584.0000 - val_loss: 11.1072 - val_accuracy: 0.0926 - val_mae: 0.2153 - val_mse: 0.0985 - val_mape: 152007680.0000\n",
      "Epoch 89/100\n",
      "1080/1080 - 0s - loss: 10.8982 - accuracy: 0.0815 - mae: 0.2154 - mse: 0.0986 - mape: 151902640.0000 - val_loss: 11.1071 - val_accuracy: 0.0926 - val_mae: 0.2153 - val_mse: 0.0985 - val_mape: 151970576.0000\n",
      "Epoch 90/100\n",
      "1080/1080 - 0s - loss: 10.8982 - accuracy: 0.0815 - mae: 0.2154 - mse: 0.0986 - mape: 151865984.0000 - val_loss: 11.0474 - val_accuracy: 0.0926 - val_mae: 0.2153 - val_mse: 0.0985 - val_mape: 151933744.0000\n",
      "Epoch 91/100\n",
      "1080/1080 - 0s - loss: 10.9131 - accuracy: 0.0824 - mae: 0.2154 - mse: 0.0985 - mape: 151829040.0000 - val_loss: 11.0474 - val_accuracy: 0.0926 - val_mae: 0.2152 - val_mse: 0.0984 - val_mape: 151896704.0000\n",
      "Epoch 92/100\n",
      "1080/1080 - 0s - loss: 10.9280 - accuracy: 0.0815 - mae: 0.2153 - mse: 0.0985 - mape: 151791824.0000 - val_loss: 11.0474 - val_accuracy: 0.0926 - val_mae: 0.2152 - val_mse: 0.0984 - val_mape: 151859424.0000\n",
      "Epoch 93/100\n",
      "1080/1080 - 0s - loss: 10.9280 - accuracy: 0.0815 - mae: 0.2153 - mse: 0.0985 - mape: 151754320.0000 - val_loss: 11.0474 - val_accuracy: 0.0926 - val_mae: 0.2152 - val_mse: 0.0984 - val_mape: 151821904.0000\n",
      "Epoch 94/100\n",
      "1080/1080 - 0s - loss: 10.9280 - accuracy: 0.0824 - mae: 0.2153 - mse: 0.0985 - mape: 151716528.0000 - val_loss: 11.0474 - val_accuracy: 0.0926 - val_mae: 0.2151 - val_mse: 0.0984 - val_mape: 151784208.0000\n",
      "Epoch 95/100\n",
      "1080/1080 - 0s - loss: 10.9280 - accuracy: 0.0824 - mae: 0.2152 - mse: 0.0985 - mape: 151678880.0000 - val_loss: 11.0473 - val_accuracy: 0.0926 - val_mae: 0.2151 - val_mse: 0.0984 - val_mape: 151746784.0000\n",
      "Epoch 96/100\n",
      "1080/1080 - 0s - loss: 10.9130 - accuracy: 0.0824 - mae: 0.2152 - mse: 0.0985 - mape: 151640992.0000 - val_loss: 11.0473 - val_accuracy: 0.0926 - val_mae: 0.2151 - val_mse: 0.0984 - val_mape: 151709408.0000\n",
      "Epoch 97/100\n",
      "1080/1080 - 0s - loss: 10.9130 - accuracy: 0.0824 - mae: 0.2152 - mse: 0.0985 - mape: 151602496.0000 - val_loss: 11.0473 - val_accuracy: 0.0926 - val_mae: 0.2150 - val_mse: 0.0984 - val_mape: 151671792.0000\n",
      "Epoch 98/100\n",
      "1080/1080 - 0s - loss: 10.9130 - accuracy: 0.0824 - mae: 0.2151 - mse: 0.0985 - mape: 151564496.0000 - val_loss: 11.0473 - val_accuracy: 0.0926 - val_mae: 0.2150 - val_mse: 0.0984 - val_mape: 151633840.0000\n",
      "Epoch 99/100\n",
      "1080/1080 - 0s - loss: 10.9130 - accuracy: 0.0824 - mae: 0.2151 - mse: 0.0985 - mape: 151524624.0000 - val_loss: 11.0473 - val_accuracy: 0.0926 - val_mae: 0.2150 - val_mse: 0.0984 - val_mape: 151595568.0000\n",
      "Epoch 100/100\n",
      "1080/1080 - 0s - loss: 10.9130 - accuracy: 0.0824 - mae: 0.2151 - mse: 0.0985 - mape: 151485664.0000 - val_loss: 11.0473 - val_accuracy: 0.0926 - val_mae: 0.2149 - val_mse: 0.0984 - val_mape: 151556960.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00        27\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       0.23      0.35      0.28        72\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.09       270\n",
      "   macro avg       0.02      0.03      0.02       270\n",
      "weighted avg       0.06      0.09      0.07       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeojin_jung/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# generate the training and test samples \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feedforward neural network\n",
    "# with ReLU activation\n",
    "ff_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(4, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.softmax, input_dim=13),\n",
    "    keras.layers.Dense(3, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(nb_classes)\n",
    "])\n",
    "\n",
    "# define loss fn as the mean squared logarithmic error\n",
    "# optimizaation fn is Adam\n",
    "# The metrics are: mae->mean absolute error\n",
    "#                  mse->mean squared error\n",
    "#                  mape->mean absolute percentage error\n",
    "#                  msle->mean squared logarithmic error\n",
    "ff_model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy', 'mae', 'mse', 'mape'])\n",
    "\n",
    "# epochs = 1000 gives the least mape in the range of 1 to 1000\n",
    "# the greater the batch_size the greater the mape\n",
    "ff_model_history = ff_model.fit(X_train, Y_train,\n",
    "                               epochs=num_epochs,\n",
    "                               batch_size=batch_size,\n",
    "                               validation_data=(X_test, Y_test),\n",
    "                               verbose=2)\n",
    "\n",
    "# predict the storage modulus using the test dataset\n",
    "y_pred = ff_model.predict_classes(X_test, batch_size = batch_size)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpQ/+r7Si9aQY9AY18pNgJ",
   "name": "feedforward_neural_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
